## airflow


1. airflow 네임 스페이스 및 key.json 기준 secret 생성

2. proxy 배포

3. helm repo add apache-airflow https://airflow.apache.org && helm repo update

4. helm upgrade airflow apache-airflow/airflow --install -f airflow-values.yaml -n airflow


## spark - connect

1. kubectl create namespace spark

2. helm repo add spark-connect https://sebastiandaberdaku.github.io/spark-connect-chart && helm repo update

3. helm upgrade --install spark-connect ./spark_connect -n spark -f spark-connect-values.yaml  => 스파크 커넥트 서버 배포

## spark - operator

1. helm repo add spark-operator https://kubeflow.github.io/spark-operator && helm repo update

2. helm upgrade --install spark-operator spark-operator/spark-operator   --namespace spark   -f spark-operator-values.yaml

## spark history server

1. kubectl create sa spark-sa -n spark

2. kubectl create secret generic spark-gcp-key \
  --from-file=key.json=/path/to/gcp-service-account.json \
  -n spark

3. echo '{}' > dummy.json
gsutil cp dummy.json gs://deq-spark-log-bucket/spark-events/.dummy

4. kubectl apply -f spark-history-server.yaml
