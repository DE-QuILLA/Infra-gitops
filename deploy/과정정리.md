## airflow


1. airflow 네임 스페이스 및 key.json 기준 secret 생성

2. proxy 배포

3. helm repo add apache-airflow https://airflow.apache.org && helm repo update

4. helm upgrade airflow apache-airflow/airflow --install -f airflow-values.yaml -n airflow


## spark - connect

1. kubectl create namespace spark

2. helm repo add spark-connect https://sebastiandaberdaku.github.io/spark-connect-chart && helm repo update

3. helm upgrade --install spark-connect ./spark_connect -n spark -f spark-connect-values.yaml  => 스파크 커넥트 서버 배포

## spark - operator

1. helm repo add spark-operator https://kubeflow.github.io/spark-operator && helm repo update

2. helm upgrade --install spark-operator spark-operator/spark-operator   --namespace spark   -f spark-operator-values.yaml

## spark history server

1. kubectl create sa spark-sa -n spark

2. kubectl create secret generic spark-gcp-key \
  --from-file=key.json=/path/to/gcp-service-account.json \
  -n spark

3. echo '{}' > dummy.json
gsutil cp dummy.json gs://deq-spark-log-bucket/spark-events/.dummy

4. kubectl apply -f spark-history-server.yaml

## kafka 

1. kubectl create ns kafka

2. helm repo add strimzi https://strimzi.io/charts/
helm repo update

3. kubectl apply -f https://strimzi.io/install/latest?namespace=kafka

4. helm upgrade --install kafka-operator strimzi/strimzi-kafka-operator   -n kafka --create-namespace -f kafka-operator-values.yaml

혹은 

```
helm install strimzi-kafka-operator strimzi/strimzi-kafka-operator \
  -n kafka \
  --set installCRDs=true \
  --create-namespace
```

5. 위 다 무시, helm upgrade --install strimzi-kafka-operator-1   ./helm_custom/strimzi-kafka-operator/   -n kafka-1 --create-namespace   -f kafka-operator-values.yaml

5. kubectl apply -f kafka-storage-class.yaml

6. kubectl apply -f kafka-cluster.yaml

7. kubectl appyl -f kafka-node-pool.yaml

8. fucking kafka cluster 완성!!!!!!!!

9. 카프카 웹 Ui

helm repo add kafka-ui https://provectus.github.io/kafka-ui-charts
helm repo update

helm upgrade --install kafka-ui kafka-ui/kafka-ui \
  -n kafka-1 \
  --set kafka.clusters[0].name="de-quilla" \
  --set kafka.clusters[0].bootstrapServers="de-quilla-kafka-cluster-kafka-bootstrap:9092" \
  --set service.type=LoadBalancer

helm upgrade --install kafka-ui kafka-ui/kafka-ui \
  -n kafka-1 \
  --set env.KAFKA_CLUSTERS_0_NAME=de-quilla \
  --set env.KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=de-quilla-kafka-cluster-kafka-bootstrap.kafka-1.svc.cluster.local:9092 \
  --set service.type=LoadBalancer

helm upgrade --install kafka-ui kafka-ui/kafka-ui   -n kafka-1   -f kafka-ui.yaml


## monitoring stacks

helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \
  -n monitoring --create-namespace \
  --set grafana.service.type=LoadBalancer \
  --set grafana.adminPassword='coffeeisnak'  # pragma: allowlist secret

kubectl apply -f kafka-export-svc.yaml

kubectyl apply -f kafka-service-monitor.yaml

de-quilla-kafka-cluster-kafka-bootstrap.kafka-1.svc.cluster.local:9092 (접근 경로 예상)

그라파나 대시보드는 여러개 import 해봤으나 딱히 괜찮은게 없었움
