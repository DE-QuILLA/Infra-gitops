#!/bin/bash
set -e
trap 'echo "âš ï¸ ë°°í¬ ì¤‘ ì—ëŸ¬ ë°œìƒ! ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨ë¨."; exit 1' ERR

# =========================
# CONFIG
# =========================
KEY_JSON_PATH="./key.json"

wait_for_pods() {
  local namespace="$1"
  echo "â³ $namespace ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  Podê°€ Running ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘..."
  while [[ $(kubectl get pods -n "$namespace" --no-headers | grep -v 'Running\|Completed' | wc -l) -gt 0 ]]; do
    sleep 5
    kubectl get pods -n "$namespace"
  done
  echo "âœ… $namespace ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  Podê°€ ì¤€ë¹„ ì™„ë£Œ!"
}

# =========================
# 1. Airflow
# =========================
echo -e "\nğŸš€ [1/3] Airflow ë°°í¬ ì‹œì‘..."

echo "ğŸ“ [Airflow] ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë° ì‹œí¬ë¦¿ êµ¬ì„± ì¤‘..."
kubectl create ns airflow --dry-run=client -o yaml | kubectl apply -f -
kubectl delete secret cloudsql-instance-credentials -n airflow --ignore-not-found
kubectl create secret generic cloudsql-instance-credentials \
    --from-file=key.json="$KEY_JSON_PATH" \
    -n airflow

# Cloud SQL Proxy ë°°í¬
echo "\nğŸ’­Cloud SQL Proxy pod ë°°í¬ ì¤‘ ..."
kubectl apply -f ./airflow/proxy-deployment.yaml -n airflow
wait_for_pods "airflow"

# Helm ì„¤ì¹˜ ë° airflow ë°°í¬
helm repo add apache-airflow https://airflow.apache.org || true
helm repo update || true
helm upgrade --install airflow apache-airflow/airflow \
  -f "./airflow/airflow-values.yaml" \
  -n airflow

# =========================
# 2. Spark
# =========================
echo -e "\nğŸš€ [2/3] Spark ë°°í¬ ì‹œì‘..."
echo "ğŸ“ [Spark] ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë° GCS ì ‘ê·¼ ê¶Œí•œ êµ¬ì„± ì¤‘..."
kubectl create ns spark --dry-run=client -o yaml | kubectl apply -f -
bash ./grant_gcs_access.sh

echo -e "\nğŸŒŸSpark Connect server ë°°í¬ ì¤‘ ..."
helm repo add sdaberdaku https://sdaberdaku.github.io/charts || true
helm repo update

helm upgrade --install spark-connect sdaberdaku/spark-connect \
  -f "./spark/spark-connect-values.yaml" \
  -n spark

# Spark Connect ì„œë²„ ë°°í¬ ëŒ€ê¸°
wait_for_pods "spark"

echo -e "\nğŸŒŸSpark Operator ë°°í¬ ì¤‘ ..."
helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
helm repo update

# Spark Operator ë°°í¬ ëŒ€ê¸°
wait_for_pods "spark"

echo -e "\nğŸŒŸSpark history ì„œë²„ ë°°í¬ ì¤‘ ..."
kubectl apply -f ./spark/spark-history-server.yaml -n spark

# Spark history ì„œë²„ ë°°í¬ ëŒ€ê¸°
wait_for_pods "spark"

# =========================
echo -e "\nğŸ‰ ëª¨ë“  ì„œë¹„ìŠ¤ ë°°í¬ ì™„ë£Œ!"
echo "ğŸ” í™•ì¸: kubectl get all --all-namespaces"
